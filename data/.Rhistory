# create open DTM filled w/ zeroes
###################################
DTM <- matrix(0, nrow=dim(speechesDF)[1], ncol=length(unique(all_words$word)))
# assign column names of DTM to be the unique words (in alpha order)
colnames(DTM) <- unique(all_words$word)
# loop over each "document"/paragraph
for(document in 1:dim(speechesDF)[1]){
# find all the words that are used in that paragraph
document_subset <- all_words[which(all_words$document==document),]
# loop over each word
for(row in 1:dim(document_subset)[1]){
# and check which column it's in
DTM[document, which(colnames(DTM)==document_subset[row, "word"] )] <- all_words[row, "count"]
}
}
###################
# distance measures
###################
# (1) squared euclidean distance function
euclidean_distance <- function(points1, points2) {
# create empty distance matrix based on size of two vectors
distanceMatrix <- matrix(NA, nrow = dim(points1)[1], ncol = dim(points2)[1])
# for each row
for(i in 1:nrow(points2)) {
# get the distance
distanceMatrix[, i] <- sqrt(rowSums(t(t(points1) - points2[i, ])^2))
}
distanceMatrix
}
###################
# k-means
###################
k_values <- 10
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(as.matrix(md), centers = i, iter.max = 35, nstart = 10)
information[i] <- KM$betweenss/KM$totss
}
k_values <- 15
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 35, nstart = 10)
information[i] <- KM$betweenss/KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained",lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")1
information
seq(1:k_values)
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
k_values <- 15
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 35, nstart = 10)
information[i] <- #KM$betweenss/
KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
k_values <- 15
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 35, nstart = 10)
information[i] <- KM$betweenss/KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
k_values <- 30
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 35, nstart = 10)
information[i] <- KM$betweenss/KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
k_values <- 30
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)
information[i] <- KM$betweenss/KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
k_values <- 30
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)
information[i] <- KM$tot.withinss # KM$betweenss/KM$totss
}
k_values <- 15
information <- rep(NA,k_values)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)
information[i] <- KM$tot.withinss # KM$betweenss/KM$totss
}
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Information Retained", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
plot(information~seq(1:k_values), type="b",pch=16, col=4, ylab="Total within-cluster sum of squares", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
# plot
plot(information~seq(1:k_values), type="b", pch=16,
ylab="Total within-cluster sum of squares", lwd=2,
xlab="Number of Clusters", main="Selecting K by elbow method")
# plot
plot(information~seq(1:k_values), type="b", pch=16,
ylab="Total Within-Cluster Sum of Squares", lwd=2,
xlab="Number of Clusters", main="Selecting K by Elbow Method")
stored_info
k_values <- 15
stored_info <- rep(NA,k_values)
set.seed(123)
for(i in 1:k_values){
KM <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)
stored_info[i] <- KM$tot.withinss # KM$betweenss/KM$totss
}
stored_info
k_values <- 15
stored_info <- NULL
set.seed(123)
for(i in 1:k_values){
stored_info[i] <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)$tot.withinss
}
# plot
plot(stored_info ~ seq(1:k_values), type="b", pch=16,
ylab="Total Within-Cluster Sum of Squares", lwd=2,
xlab="Number of Clusters", main="Selecting K by Elbow Method")
# set number of clusters
k_values <- 15
# open blank vector to fill
KM <- list()
stored_info <- NULL
# make reproducible
set.seed(12345)
# for each cluster
for(i in 1:k_values){
# stroe the total within SoS
KM[[i]] <- kmeans(DTM, centers = i, iter.max = 50, nstart = 10)
stored_info[i] <- KM$tot.withinss
}
KM[1]
KM[15]
KM[15]$cluster
KM[15]
KM[[15]]$cluster
KM[[15]]$centers
dim(KM[[15]]$centers)
which(KM[[15]]$centers==1)
length(which(KM[[15]]$centers==1))
length(which(KM[[1]]$centers==1))
length(which(KM[[2]]$centers==1))
KM[[2]]
KM[[2]]$cluster
KM[[15]]$centers
unique(KM[[15]]$centers)
numeric(KM[[15]]$centers)
str(KM[[15]]$centers)
dim(DTM)
training_set <- DTM[1:60, ]
test_set <- DTM[61:dim(DTM)[1], ]
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL) {
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers=NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers=NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers=NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k=1, n_iter=1, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers=NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers=NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(centers==NULL){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(is.null(centers)){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# execute function
our_output <- K_means(DTM, k=2, n_iter=10)
our_output
our_output$clusters
# run on training set
training_model <- K_means(training_set, k=2, n_iter=50)
training_model$centers
training_model
training_model$centers
dim(training_model)
dim(training_model$centers)
length(training_model$centers)
training_model$centers[length(training_model$centers)]
dim(training_model$centers[length(training_model$centers)])
length(training_model$centers[length(training_model$centers)])
training_model$centers[length(training_model$centers)]
test <- training_model$centers[length(training_model$centers)]
View(test)
training_model$centers[length(training_model$centers)][[1]]
dim(training_model$centers[length(training_model$centers)][[1]])
training_model$centers[length(training_model$centers)][[1]]
training_model$centers[length(training_model$centers)]
length(training_model$centers)
test_model <- K_means(training_set, k=2, n_iter=50, centers=training_model$centers[length(training_model$centers)][[1]])
View(test_model)
View(test_model)
test_model$clusters
test_model
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_model$centers[length(training_model$centers)][[1]])
training_model$centers[length(training_model$centers)][[1]]
test_set
training_model$centers[length(training_model$centers)][[1]]
dim(training_model$centers[length(training_model$centers)][[1]])
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(is.null(centers)){
centers <- x[sample(nrow(x), k),]
}
browser()
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# partition both sets
training_set <- DTM[1:60, ]
test_set <- DTM[61:dim(DTM)[1], ]
# run on training set
training_model <- K_means(training_set, k=2, n_iter=50)
centers
dim(centers)
training_model$centers[length(training_model$centers)][[1]]
dim(training_model$centers[length(training_model$centers)][[1]])
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(is.null(centers)){
centers <- x[sample(nrow(x), k),]
}
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# execute function
our_output <- K_means(DTM, k=2, n_iter=10)
# partition both sets
training_set <- DTM[1:60, ]
test_set <- DTM[61:dim(DTM)[1], ]
# run on training set
training_model <- K_means(training_set, k=2, n_iter=50)
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_model$centers[length(training_model$centers)][[1]])
test
test <- training_model$centers[length(training_model$centers)][[1]]
View(test)
str(test)
as.matrix(test)
str(as.matrix(test))
test_model <- K_means(test_set, k=2, n_iter=50, centers=as.matrix(training_model$centers[length(training_model$centers)][[1]]))
training_centers <- training_model$centers[length(training_model$centers)][[1]]
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_centers)
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(is.null(centers)){
centers <- x[sample(nrow(x), k),]
}
browser()
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_centers)
x
dim(x)
dim(centers)
str(centers)
str(x)
rownames(training_centers) <- c()
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_centers)
# (2) define k-means algorithm
K_means <- function(x, k, n_iter, centers=NULL){
# create empty vectorized lists based on the size of iterations
clusterHistory <- vector(n_iter, mode="list")
centerHistory <- vector(n_iter, mode="list")
# generate starting centers
# sample some centers, 5 for example
if(is.null(centers)){
centers <- x[sample(nrow(x), k),]
}
# browser()
# iterate for set number of times
for(i in 1:n_iter) {
# calculate distance of each word from center
distances_to_centers <- euclidean_distance(x, centers)
# assign to closest cluster (min)
clusters <- apply(distances_to_centers, 1, which.min)
# reupdate where the center of the cluster is
centers <- apply(x, 2, tapply, clusters, mean)
# save each clust and center for next step
clusterHistory[[i]] <- clusters
centerHistory[[i]] <- centers
}
# return list of clusters and centers
list(clusters=clusterHistory, centers=centerHistory)
}
# partition both sets
training_set <- DTM[1:60, ]
test_set <- DTM[61:dim(DTM)[1], ]
# run on training set
training_model <- K_means(training_set, k=2, n_iter=50)
training_centers <- training_model$centers[length(training_model$centers)][[1]]
rownames(training_centers) <- c()
test_model <- K_means(test_set, k=2, n_iter=50, centers=training_centers)
